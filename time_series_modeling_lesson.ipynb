{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting \n",
    "\n",
    "\n",
    "In this lesson, we will practice forecasting using the following methods:  \n",
    "\n",
    "- **Last observed value**  \n",
    "- **Simple average**  \n",
    "- **Moving average**\n",
    "- **Previous cycle** \n",
    "- **Holt's linear trend**  \n",
    "- **Holt's seasonal trend**\n",
    " \n",
    "\n",
    "______________________________\n",
    "\n",
    "\n",
    "We will acquire and prepare store sales data stored in our Codeup MySQL server, then forecast using the modeling approached listed above and evaluate performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for presentation purposes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# wrangle\n",
    "from env import user, password, host\n",
    "import os\n",
    "\n",
    "# transform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualize \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# working with dates\n",
    "from datetime import datetime\n",
    "\n",
    "# modeling\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import Holt, ExponentialSmoothing\n",
    "np.random.seed(0)\n",
    "\n",
    "# evaluate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will acquire the data from our MySQL server and run the following prepare steps:\n",
    "- Convert the `sale_date` column to be a datetime type\n",
    "- Set the `sale_date` column as our index\n",
    "- Rename `sale_amount` to `quantity` for clarity\n",
    "- Create a new field called `sales_total` that is the product of `quantity` and `item_price`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_url(database):\n",
    "    '''\n",
    "    Returns a formatted string using credentials stored in env.py that can be passed to a pd.read_sql() function\n",
    "    '''\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{database}'\n",
    "    \n",
    "def get_store_data():\n",
    "    '''\n",
    "    Returns a dataframe of all store data in the tsa_item_demand database and saves a local copy as a csv file.\n",
    "    '''\n",
    "    query = '''\n",
    "            SELECT *\n",
    "            FROM items\n",
    "            JOIN sales USING(item_id)\n",
    "            JOIN stores USING(store_id)\n",
    "            '''\n",
    "    \n",
    "    df = pd.read_sql(query, get_db_url('tsa_item_demand'))\n",
    "    df.to_csv('tsa_store_data.csv', index=False)\n",
    "    return df\n",
    "\n",
    "def wrangle_store_data():\n",
    "    '''\n",
    "    Checks for a local cache of tsa_store_data.csv and if not present will run the get_store_data() function which acquires data from Codeup's mysql server\n",
    "    '''\n",
    "    filename = 'tsa_store_data.csv'\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        df = get_store_data()\n",
    "    return df\n",
    "\n",
    "def prep_store_data(df):\n",
    "    '''\n",
    "    Prepares raw store data for analysis and time series modeling.\n",
    "    '''\n",
    "    df.sale_date = pd.to_datetime(df.sale_date)\n",
    "    df = df.set_index('sale_date').sort_index()\n",
    "    df = df.rename(columns={'sale_amount': 'quantity'})\n",
    "    df['sales_total'] = df.quantity * df.item_price\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle_store_data()\n",
    "df = prep_store_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of the details of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of our modeling, we will only work with one variable at a time (univariate). To this end, we can resample our dataframe to a daily time period, aggregating only the `quantity` and `sales_total` fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled = df.resample('d')[['quantity','sales_total']].sum()\n",
    "df_resampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split\n",
    "\n",
    "We will use a percentage based approach to splitting our time series data.  \n",
    "1. Identify the total length of the dataframe and multiply by our desired perentage to get the number of rows that equates to the first x% of the dataframe, which equates to the first x% of the time covered in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set train size to be 50% of total \n",
    "train_size = int(round(df_resampled.shape[0] * 0.5))\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set validate size to be 30% of total \n",
    "validate_size = int(round(df_resampled.shape[0] * 0.3))\n",
    "validate_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set test size to be number of rows remaining. \n",
    "test_size = int(round(df_resampled.shape[0] * 0.2))\n",
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_resampled) == train_size + validate_size + test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate will go from 913 to 913+548\n",
    "validate_end_index = train_size + validate_size\n",
    "validate_end_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Slice our dataframe using the index positions we identified for each section in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train will go from 0 to 912\n",
    "train = df_resampled[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last observation for train occurred on `2015-07-02`. We will want to make sure that the first observation for validate is the very next day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate will go from 912 to 1458\n",
    "validate = df_resampled[train_size:validate_end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first observation for validate is `2015-07-03`. This means there is no gap in dates between train and validate. Likewise, we will want to make sure that the last observation in validate is adjacent to the first observation in test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test will include 1459 to the end\n",
    "test = df_resampled[validate_end_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape[0], validate.shape[0], test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify Splits**\n",
    "\n",
    "Does the length of each df equate to the length of the original df? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is len of train + validate + test == lenght of entire dataframe. \n",
    "len(train) + len(validate) + len(test) == len(df_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the first row of original df equate to the first row of train? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_resampled.head(1) == train.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the last row of test the same as the last row of our original dataframe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([test.tail(1), df_resampled.tail(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our data first, viewing where the data is split into train and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plt.figure(figsize=(14,8))\n",
    "    plt.plot(train[col], color='#377eb8', label = 'Train')\n",
    "    plt.plot(validate[col], color='#ff7f00', label = 'Validate')\n",
    "    plt.plot(test[col], color='#4daf4a', label = 'Test')\n",
    "    plt.legend()\n",
    "    plt.ylabel(col)\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Helpful Evaluation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we try out different methods for forecasting sales and number of items sold, let's create a couple of functions that will be helpful in evaluating each of the modeling approaches we will use. \n",
    "\n",
    "`evaluate()` will compute the Mean Squared Error and the Root Mean Squared Error of our predictions compared to the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(target_var):\n",
    "    '''\n",
    "    This function will take the actual values of the target_var from validate, \n",
    "    and the predicted values stored in yhat_df, \n",
    "    and compute the rmse, rounding to 0 decimal places. \n",
    "    it will return the rmse. \n",
    "    '''\n",
    "    rmse = round(sqrt(mean_squared_error(validate[target_var], yhat_df[target_var])), 0)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plot_and_eval()` will use the evaluate function and also plot train and test values with the predicted values in order to visualize our performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_eval(target_var):\n",
    "    '''\n",
    "    This function takes in the target var name (string), and returns a plot\n",
    "    of the values of train for that variable, validate, and the predicted values from yhat_df. \n",
    "    it will als lable the rmse. \n",
    "    '''\n",
    "    plt.figure(figsize = (12,4))\n",
    "    plt.plot(train[target_var], label='Train', linewidth=1, color='#377eb8')\n",
    "    plt.plot(validate[target_var], label='Validate', linewidth=1, color='#ff7f00')\n",
    "    plt.plot(yhat_df[target_var], label='yhat', linewidth=2, color='#a65628')\n",
    "    plt.legend()\n",
    "    plt.title(target_var)\n",
    "    rmse = evaluate(target_var)\n",
    "    print(target_var, '-- RMSE: {:.0f}'.format(rmse))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are planning on evaluating a lot of models. Let's create an easy to read dataframe called `eval_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe\n",
    "eval_df = pd.DataFrame(columns=['model_type', 'target_var', 'rmse'])\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than manually appending the results of each model, we can create a function that will do it for us. \n",
    "\n",
    "`append_eval_df(model_type)` will append evaluation metrics for each model into our `eval_df` data frame object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to store the rmse so that we can compare\n",
    "def append_eval_df(model_type, target_var):\n",
    "    '''\n",
    "    this function takes in as arguments the type of model run, and the name of the target variable. \n",
    "    It returns the eval_df with the rmse appended to it for that model and target_var. \n",
    "    '''\n",
    "    rmse = evaluate(target_var)\n",
    "    d = {'model_type': [model_type], 'target_var': [target_var],\n",
    "        'rmse': [rmse]}\n",
    "    d = pd.DataFrame(d)\n",
    "    return eval_df.append(d, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast \n",
    "\n",
    "Forecasting is another word for predicting time series data. As a reminder, we will work with the following approaches:\n",
    "\n",
    "#### Baseline Models\n",
    "1. Last Observed Value\n",
    "2. Simple Average\n",
    "3. Moving Average\n",
    "\n",
    "#### Non-Baseline Models\n",
    "4. Previous Cycle\n",
    "5. Holt's Linear Trend\n",
    "6. Holt's Seasonal Trend\n",
    "\n",
    "\n",
    "## Last Observed Value\n",
    "\n",
    "The simplest method for forecasting is to predict all future values to be the last observed value.  \n",
    "\n",
    "### Make Predictions\n",
    "\n",
    "What was the last observed value for `sales_total` in our training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sales_total'][-1:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the last item of sales total and assign to variable\n",
    "last_sales = train['sales_total'][-1:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the last observed value for `quantity` in our training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the last item of quantity and assign to variable\n",
    "last_quantity = train['quantity'][-1:][0]\n",
    "last_quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a dataframe containing our predictions (which will all be the same value with this baseline approach):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = pd.DataFrame(\n",
    "    {'sales_total': [last_sales],\n",
    "     'quantity': [last_quantity]},\n",
    "    index=validate.index)\n",
    "\n",
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of `.describe()` confims that every predicted value is the same.  \n",
    "\n",
    "### Plot Actual vs. Predicted Values\n",
    "\n",
    "Let's plot actual and predicted values using our `plot_and_eval()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate** \n",
    "\n",
    "Evaluate using MSE and RMSE, and add evaluation metrics to `eval_df`. We can use our `append_eval_df` function to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type = 'last_observed_value', \n",
    "                             target_var = col)\n",
    "\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Average\n",
    "\n",
    "Take the simple average of historical values in train and use that value to predict future values.   \n",
    "\n",
    "This is another good option for an initial baseline. Every predicted period (those in 'test') will be assigned the same value (the average of the entire training set).  \n",
    "\n",
    "**Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute simple average of sales_total (from train data)\n",
    "avg_sales = round(train['sales_total'].mean(), 2)\n",
    "avg_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute simple average of quantity (from train data)\n",
    "avg_quantity = round(train['quantity'].mean(), 2)\n",
    "avg_quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction for the value of `sales_total` and `quantity`, stored as the dataframe `yhat_df` for every day of the validate index. We can turn this into a function for ease of continued use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_baseline_predictions(sales_predictions=None, quantity_predictions=None):\n",
    "    yhat_df = pd.DataFrame({'sales_total': [sales_predictions],\n",
    "                           'quantity': [quantity_predictions]},\n",
    "                          index=validate.index)\n",
    "    return yhat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = make_baseline_predictions(avg_sales, avg_quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Actual vs. Predicted Values\n",
    "\n",
    "Similar to our handling of the previous baseline model, we can plot our `yhat_df` values against the actual values in validate. Our `plot_and_eval()` function accomplishes this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "Evaluate using MSE and RMSE, and add evaluation metrics to `eval_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type='simple_average', \n",
    "                            target_var = col)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Average\n",
    "\n",
    "In this example, we will use a 30-day moving average to forecast. In other words, the average over the last 30-days will be used as the forecasted value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Predictions**\n",
    "\n",
    "There could be several ways to obtain the value of the last 30 periods in `train`. We will use the `.rolling()` method to accomplish this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period=30\n",
    "train['sales_total'].rolling(period).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.rolling()` gives us an array of moving averages. We will only need the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period=30\n",
    "train['sales_total'].rolling(period).mean()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the last 30 day moving average for each column\n",
    "rolling_sales = round(train['sales_total'].rolling(period).mean()[-1], 2)\n",
    "rolling_quantity = round(train['quantity'].rolling(period).mean()[-1], 2)\n",
    "print(rolling_sales, rolling_quantity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our `make_baseline_predictions()` function to create the newest version of the `yhat_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = make_baseline_predictions(rolling_sales, rolling_quantity)\n",
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Actual vs. Predicted Values\n",
    "\n",
    "Now, let's plot and evaluate the performance of our time series model using **Moving Average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "Evaluate using MSE and RMSE, and add evaluation metrics to `eval_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type = '30d_moving_avg', \n",
    "                            target_var = col)\n",
    "\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out several other values for our period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [4, 12, 26, 52, 104]\n",
    "\n",
    "for p in periods: \n",
    "    rolling_sales = round(train['sales_total'].rolling(p).mean()[-1], 2)\n",
    "    rolling_quantity = round(train['quantity'].rolling(p).mean()[-1], 2)\n",
    "    yhat_df = make_baseline_predictions(rolling_sales, rolling_quantity)\n",
    "    model_type = str(p) + '_day_moving_avg'\n",
    "    for col in train.columns:\n",
    "        eval_df = append_eval_df(model_type = model_type,\n",
    "                                target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is best so far? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_quantity_rmse = eval_df[eval_df.target_var == 'quantity']['rmse'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_quantity_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[eval_df.rmse == best_quantity_rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_sales_total_rmse = eval_df[eval_df.target_var == 'sales_total']['rmse'].min()\n",
    "\n",
    "eval_df[eval_df.rmse == best_sales_total_rmse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as baselines are concerned, it looks like our 104 day moving average is a good starting point for comparisons.\n",
    "\n",
    "# Non-Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holt-Winters\n",
    "\n",
    "Two of the models that we will evaluate are based on Holt-Winters, which models on three elements:\n",
    "- A typical value (average)\n",
    "- A slope (trend) over time\n",
    "- And a cyclical repeating pattern (seasonality)\n",
    "\n",
    "This means that its worth looking at a seasonal decomposition plot of our target, to inspect these components:\n",
    "\n",
    "**Seasonal Decomposition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    sm.tsa.seasonal_decompose(train[col].resample('W').mean()).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there is both strong seasonality and a notable trend in both targets (`sales_total` and `quantity`). There are two Holt-Winters models that we will attempt\n",
    "- Holt's Linear Model\n",
    "- Holt's Seasonal Model\n",
    "\n",
    "### Holt's Linear Model\n",
    "\n",
    "Our approach will be similar to many other modeling processes we have performed:\n",
    "1. Create the object: `Holt()`\n",
    "2. Fit the object: `.fit()`\n",
    "3. Make predictions: `.predict()`\n",
    "\n",
    "The first set of hyperparameters are set when we call `Holt()`: \n",
    "\n",
    "- **exponential** = True/False (exponential vs. linear growth, additive vs. multiplicative)\n",
    "- **damped $\\phi$** = True/False\n",
    "    - with Holt, forecasts tend to increase or decrease indefinitely into the future.  To avoid absurd long term predictions, use the Damped method (True) which sets a damping parameter between 0< Ï• <1. \n",
    "\n",
    "A second set of hyperparameters are set when we call `.fit()`: \n",
    "\n",
    "- **smoothing_level ($\\alpha$)**: value between (0,1)\n",
    "    - Closer to 0, the level doesn't change with each new observation\n",
    "    - Closer to 1, the level reacts strongly with each new observation\n",
    "- **smoothing_slope ($\\beta$)**: value between (0,1)\n",
    "    - Closer to 0, trend is not changing over time\n",
    "    - Closer to 1, trend is changing significantly over time\n",
    "- **optimized**: use the auto-optimization that allow statsmodels to automatically find an optimized value for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'sales_total' \n",
    "# create our Holt Object\n",
    "model = Holt(train[col], exponential=False, damped=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the Holt object\n",
    "model = model.fit(optimized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_sales_total = model.predict(start = validate.index[0],\n",
    "                              end = validate.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_sales_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've successfully created an array of predictions on the validate set for `sales_total`. Lets run a loop that will create a dataframe of predictions for every column in our training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing this in a loop for each column\n",
    "for col in train.columns:\n",
    "    model = Holt(train[col], exponential=False, damped=True)\n",
    "    model = model.fit(optimized=True)\n",
    "    yhat_values = model.predict(start = validate.index[0],\n",
    "                              end = validate.index[-1])\n",
    "    yhat_df[col] = round(yhat_values, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Actual vs. Predicted Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(target_var = col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just from visual inspection, Holt's Linear Trend doesn't seem to be that much better than our other baselines. It fails to adequately predict the strong seasonality present in our data. This is not surprising. Holt's Linear Trend tends to work better with data with a strong trend and limited variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type = 'holts_optimized', \n",
    "                            target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.sort_values(by='rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holt's Seasonal Trend\n",
    "\n",
    "Holt's Seasonal Trend is started by using `ExponentialSmoothing()`\n",
    "\n",
    "The process is similar to our previous model:\n",
    "1. Create the object: `ExponentialSmoothing()`\n",
    "2. Fit the object: `.fit()`\n",
    "3. Make predictions: `.forecast()`\n",
    "\n",
    "This function has several hyperparameters:\n",
    "- **seasonal_periods**: The number of periods representing one cycle of seasonality. This is why performing a decomposition plot can be valuable, as this number needs to be entered manually.\n",
    "- **trend**: Whether the overall trend is additive (`trend='add'`) or multiplicative (`trend='mul'`)\n",
    "- **seasonal**: Whether the seasonality is additive (`seasonal='add'`) or multiplicative (`seasonal='mul'`)\n",
    "- **damped**: If we want the trend to reduce over the length of the forecast to avoid absurd long term predictions, we can set `damped=True`\n",
    "\n",
    "Given our smaller dataset, rather than choosing any one combination of hyperparameters, we can create multiple models to test different combinations:\n",
    "\n",
    "___\n",
    "<center>Quantity</center>\n",
    "\n",
    "|model_name|seasonal_periods|trend|seasonal|damped|\n",
    "|---|---|---|---|---|\n",
    "|hst_quantity_fit1|365|add|add|False|\n",
    "|hst_quantity_fit2|365|add|mul|False|\n",
    "|hst_quantity_fit3|365|add|add|True|\n",
    "|hst_quantity_fit4|365|add|mul|True|\n",
    "\n",
    "___\n",
    "<center>Sales Total</center>\n",
    "\n",
    "|model_name|seasonal_periods|trend|seasonal|damped|\n",
    "|---|---|---|---|---|\n",
    "|hst_sales_fit1|365|add|add|False|\n",
    "|hst_sales_fit2|365|add|mul|False|\n",
    "|hst_sales_fit3|365|add|add|True|\n",
    "|hst_sales_fit4|365|add|mul|True|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models for quantity\n",
    "hst_quantity_fit1 = ExponentialSmoothing(train.quantity, seasonal_periods=365, trend='add', seasonal='add').fit()\n",
    "hst_quantity_fit2 = ExponentialSmoothing(train.quantity, seasonal_periods=365, trend='add', seasonal='mul').fit()\n",
    "hst_quantity_fit3 = ExponentialSmoothing(train.quantity, seasonal_periods=365, trend='add', seasonal='add', damped=True).fit()\n",
    "hst_quantity_fit4 = ExponentialSmoothing(train.quantity, seasonal_periods=365, trend='add', seasonal='mul', damped=True).fit()\n",
    "\n",
    "# Models for sales\n",
    "hst_sales_fit1 = ExponentialSmoothing(train.sales_total, seasonal_periods=365, trend='add', seasonal='add').fit()\n",
    "hst_sales_fit2 = ExponentialSmoothing(train.sales_total, seasonal_periods=365, trend='add', seasonal='mul').fit()\n",
    "hst_sales_fit3 = ExponentialSmoothing(train.sales_total, seasonal_periods=365, trend='add', seasonal='add', damped=True).fit()\n",
    "hst_sales_fit4 = ExponentialSmoothing(train.sales_total, seasonal_periods=365, trend='add', seasonal='mul', damped=True).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If curious, we can visualize the hyperparameters and coefficients set for each of our models by using `.params`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hst_quantity_fit1.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will also contain a SSE attribute that we can use to compare performance. We can derive RMSE from SSE, but for now, we can just use SSE to look at the relative performance of our Holt's Seasonal Trend models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_quantity=pd.DataFrame({'model':['hst_quantity_fit1', 'hst_quantity_fit2', 'hst_quantity_fit3', 'hst_quantity_fit4'],\n",
    "                              'SSE':[hst_quantity_fit1.sse, hst_quantity_fit2.sse, hst_quantity_fit3.sse, hst_quantity_fit4.sse]})\n",
    "results_quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_quantity.sort_values(by='SSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For quantity, the 1st version of our Holt's Seasonal Trend model (`trend='add', seasonal='add', damped=False`) is the best performing of the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sales=pd.DataFrame({'model':['hst_sales_fit1', 'hst_sales_fit2', 'hst_sales_fit3', 'hst_sales_fit4'],\n",
    "                              'SSE':[hst_sales_fit1.sse, hst_sales_fit2.sse, hst_sales_fit3.sse, hst_sales_fit4.sse]})\n",
    "results_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sales.sort_values(by='SSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for `sales_total`, the 1st version of our Holt's Seasonal Trend model (`trend='add', seasonal='add', damped=False`) is the best performing of the group.\n",
    "\n",
    "### Make Predictions\n",
    "\n",
    "The `.forecast()` method for Holt's Seasonal models requires the number of periods the model is going to provide a prediction for **after** the end of the training data. \n",
    "\n",
    "In other words `.forecast(2)` would provide predictions for `2015-07-03` and `2015-07-04`. Therefore, we can get predictions for every day in our validate index by passing the number of rows in validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = pd.DataFrame({'sales_total': hst_sales_fit1.forecast(validate.shape[0]),\n",
    "                           'quantity': hst_quantity_fit1.forecast(validate.shape[0])},\n",
    "                          index=validate.index)\n",
    "yhat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type = 'holts_seasonal_add_add', \n",
    "                            target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.sort_values(by='rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best implementation of Holt's Seasonal Trend is significantly outperforming all other models made thus far.\n",
    "\n",
    "## Previous Cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take all the 2016 data points, compute the daily delta, year-over-year, average that delta over all the days, and adding that average to the previous year's value on a day will give you the forecast for that day. \n",
    "\n",
    "If a primary cycle is weekly, then you may want to do this on a week-over-week cadence. \n",
    "\n",
    "In the below example:  \n",
    "1. Compute the 365 average year over year differences from 2013 through 2015\n",
    "2. Add that average delta to the values during 2015. \n",
    "3. Set the index in your yhat dataframe to represent the dates those predictions are make for. \n",
    "\n",
    "Let's get started....\n",
    "\n",
    "**Re-split data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_resampled[:'2015']\n",
    "validate = df_resampled['2016']\n",
    "test = df_resampled['2017']\n",
    "\n",
    "print(train.shape)\n",
    "print(validate.shape)\n",
    "print(test.shape)\n",
    "\n",
    "train.head()\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.diff(365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the year-over-year difference for each day from 2013 to 2015\n",
    "# taking the mean, and then adding that value to the daily 2015 values. \n",
    "\n",
    "# find yoy diff. from 2013-2014 and 2014-2015, take the mean, and add to each value in 2015. \n",
    "yhat_df = train['2015'] + train.diff(365).mean()\n",
    "yhat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.diff(365).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc['2015'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's peek into the prediction we will make for 1/1/2016\n",
    "# by comparing the predicted value \n",
    "# (2015 value + year-over-year average difference)\n",
    "# to the actual 1/1/2016 value\n",
    "pd.concat([yhat_df.head(1), validate.head(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set yhat_df to index of validate\n",
    "yhat_df.index = validate.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.shape # A leap year!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = validate[validate.index != '2016-02-29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set yhat_df to index of validate\n",
    "# yhat_df: 2015 values + the mean year over year difference for the entire training dataset\n",
    "yhat_df.index = validate.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot and Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(target_var = col)\n",
    "    eval_df = append_eval_df(model_type = \"previous_year\", \n",
    "                            target_var = col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Which model did the best? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.sort_values(by='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_total_min_rmse = eval_df.groupby('target_var')['rmse'].min()[0]\n",
    "\n",
    "quantity_min_rmse = eval_df.groupby('target_var')['rmse'].min()[1]\n",
    "\n",
    "# find which model that is\n",
    "eval_df[((eval_df.rmse == sales_total_min_rmse) | \n",
    "         (eval_df.rmse == quantity_min_rmse))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Test\n",
    "\n",
    "Now that we have identified our one best model for each target variable, we can evaluate its peformance on our test data. As a reminder, `.forecast()` allows us to make predictions, but the method always starts after the end of the training data. To get to the test data, we will need to increase the number of periods being predicted to be equal to the combined periods of validate and test. \n",
    "\n",
    "We altered our train-validate-test split to perform the previous cycle approach. Let's reset to the original train-validate-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_resampled[:train_size]\n",
    "validate = df_resampled[train_size:validate_end_index]\n",
    "test = df_resampled[validate_end_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = pd.DataFrame({'sales_total': hst_sales_fit1.forecast(validate.shape[0] + test.shape[0]),\n",
    "                           'quantity': hst_quantity_fit1.forecast(validate.shape[0] + test.shape[0])})\n",
    "yhat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original test set started on 2017-01-01, so we can slice out that portion from our `yhat_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = yhat_df['2017-01-01':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_plot(target_var):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(train[target_var], color='#377eb8', label='train')\n",
    "    plt.plot(validate[target_var], color='#ff7f00', label='validate')\n",
    "    plt.plot(test[target_var], color='#4daf4a',label='test')\n",
    "    plt.plot(yhat_df[target_var], color='#a65628', label='yhat')\n",
    "    plt.legend()\n",
    "    plt.title(target_var)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_sales_total = sqrt(mean_squared_error(test['sales_total'], \n",
    "                                       yhat_df['sales_total']))\n",
    "\n",
    "rmse_quantity = sqrt(mean_squared_error(test['quantity'], \n",
    "                                       yhat_df['quantity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('FINAL PERFORMANCE OF MODEL ON TEST DATA')\n",
    "print('rmse-sales total: ', rmse_sales_total)\n",
    "print('rmse-quantity: ', rmse_quantity)\n",
    "for col in train.columns:\n",
    "    final_plot(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our RMSE of our final model did get noticably worse on the test data. Its possible that while the performance of the model starts high, it degrades the further out it projects. Let's take a look at what a projection into 2018 would look like.\n",
    "\n",
    "## Forcasting Into Future\n",
    "\n",
    "Predicting 2018 simply requires us to extend the value passed to `.forecast()` by an additional 365 periods and then slicing out what we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = pd.DataFrame({'sales_total': hst_sales_fit1.forecast(validate.shape[0] + test.shape[0] + 365),\n",
    "                           'quantity': hst_quantity_fit1.forecast(validate.shape[0] + test.shape[0] + 365)})\n",
    "forecast = forecast['2018':]\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_plot(target_var):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(train[target_var], color='#377eb8', label='Train')\n",
    "    plt.plot(validate[target_var], color='#ff7f00', label='Validate')\n",
    "    plt.plot(test[target_var], color='#4daf4a', label='Test')\n",
    "    plt.plot(yhat_df[target_var], color='#a65628', label='yhat')\n",
    "    plt.plot(forecast[target_var], color='#984ea3', label='Forecast')\n",
    "    plt.title(target_var)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    final_plot(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set was made of synthetic data with a clear and observable pattern. It allows us to observe the risk of long term performance degredation. While `Holt's Seasonal Trend` outperformed `Previous Cycle` on validate, `Previous Cycle` would have probably been the best model to use. `Holt's Seasonal Trend` is failing to demonstrate the higher maximum value in each subsequent cycle. \n",
    "\n",
    ">**However, I can be confident in this claim because I have atypical knowledge that this data is extremely predictable. Real data is rarely as reliable, and conclusions are almost never as clear as the example we have shown here. Being overconfident about predicting the future is a sure way to get noticed, but maybe not in the way that you would like.** \n",
    "\n",
    "Forecasting is an art as much as it is a science, as the environment that created the values of our historical data may be very different from the environment that creates future values. \n",
    "\n",
    ">**\"It's tough to make predictions, especially about the future.\" - Yogi Berra**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "The end result of this exercise should be a Jupyter notebook named `model`.\n",
    "\n",
    "Using [saas.csv](https://ds.codeup.com/saas.csv) or log data from API usage\n",
    "\n",
    "1. Split data (train/test) and resample by any period, except daily, and aggregate using the sum. \n",
    "2. Forecast, plot and evaluate using each at least 4 of the methods we discussed:\n",
    "    - Last Observed Value\n",
    "    - Simple Average\n",
    "    - Moving Average\n",
    "    - Holt's Linear Trend \n",
    "    - Holt's Seasonal Trend\n",
    "    - Based on previous year/month/etc., this is up to you.\n",
    "\n",
    "Bonus: \n",
    "1. Using the store item demand data, create a forecast of `sales_total` and `quantity` for 2018 using the `Previous Cycle` approach.  .  \n",
    "2. Predict 2018 total **monthly** sales for a single store and/or item by creating a model using prophet.\n",
    "3. Return a dataframe with the month, store_id, y-hat, and the confidence intervals (y-hat lower, y-hat upper).\n",
    "4. Plot the 2018 monthly sales predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
